{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.24.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from scikit-learn) (3.1.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.11 -m pip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (3.7.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from matplotlib) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from matplotlib) (4.39.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.24.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from matplotlib) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from matplotlib) (9.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/opt/six/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.11 -m pip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "digits = sk.datasets.load_digits()\n",
    "print(digits)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "print(digits.data.shape)\n",
    "print(len(digits.feature_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x300 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split data into 80% train and 20% test subsets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data, digits.target, test_size=0.2, shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import nn\n",
    "\n",
    "nn_arch = [{'input_dim': 64, 'output_dim': 16, 'activation': 'relu'}, {'input_dim': 16, 'output_dim': 64, 'activation': 'sigmoid'}]\n",
    "\n",
    "autoencoder = nn.NeuralNetwork(nn_arch, lr=0.05, seed=42, batch_size=100, epochs=10, loss_function='binary cross entropy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_curr dim is:  (16, 64)\n",
      "W_curr dim is:  (64, 16)\n",
      "A_curr is:  [[1 1 1 ... 0 1 0]\n",
      " [1 0 1 ... 0 1 0]\n",
      " [1 1 1 ... 0 1 0]\n",
      " ...\n",
      " [1 0 1 ... 0 1 1]\n",
      " [1 1 1 ... 0 1 1]\n",
      " [1 1 1 ... 1 1 0]]\n",
      "y len:  96\n",
      "y_hat len:  96\n",
      "y_hat:  [[9.99999999e-01 9.99999999e-01 9.99999999e-01 ... 1.00000000e-09\n",
      "  9.99999999e-01 1.00000000e-09]\n",
      " [9.99999999e-01 1.00000000e-09 9.99999999e-01 ... 1.00000000e-09\n",
      "  9.99999999e-01 1.00000000e-09]\n",
      " [9.99999999e-01 9.99999999e-01 9.99999999e-01 ... 1.00000000e-09\n",
      "  9.99999999e-01 1.00000000e-09]\n",
      " ...\n",
      " [9.99999999e-01 1.00000000e-09 9.99999999e-01 ... 1.00000000e-09\n",
      "  9.99999999e-01 9.99999999e-01]\n",
      " [9.99999999e-01 9.99999999e-01 9.99999999e-01 ... 1.00000000e-09\n",
      "  9.99999999e-01 9.99999999e-01]\n",
      " [9.99999999e-01 9.99999999e-01 9.99999999e-01 ... 9.99999999e-01\n",
      "  9.99999999e-01 1.00000000e-09]]\n",
      "W_curr dim is:  (16, 64)\n",
      "W_curr dim is:  (64, 16)\n",
      "A_curr is:  [[1 1 1 ... 0 1 0]\n",
      " [1 0 1 ... 0 1 0]\n",
      " [1 1 1 ... 0 1 0]\n",
      " ...\n",
      " [1 0 1 ... 0 1 1]\n",
      " [1 1 1 ... 0 1 1]\n",
      " [1 1 1 ... 1 1 0]]\n",
      "dA_curr in BCE:  [[1.04166667e+05 1.04166667e+05 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166677e-02]\n",
      " [1.04166667e+05 1.04166677e-02 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166677e-02]\n",
      " [1.04166667e+05 1.04166667e+05 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166677e-02]\n",
      " ...\n",
      " [1.04166667e+05 1.04166677e-02 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166667e+05]\n",
      " [1.04166667e+05 1.04166667e+05 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166667e+05]\n",
      " [1.04166667e+05 1.04166667e+05 1.04166667e+05 ... 1.04166667e+05\n",
      "  1.04166667e+05 1.04166677e-02]]\n",
      "dA_curr in sigmoid:  [[1.04166667e+05 1.04166667e+05 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166677e-02]\n",
      " [1.04166667e+05 1.04166677e-02 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166677e-02]\n",
      " [1.04166667e+05 1.04166667e+05 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166677e-02]\n",
      " ...\n",
      " [1.04166667e+05 1.04166677e-02 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166667e+05]\n",
      " [1.04166667e+05 1.04166667e+05 1.04166667e+05 ... 1.04166677e-02\n",
      "  1.04166667e+05 1.04166667e+05]\n",
      " [1.04166667e+05 1.04166667e+05 1.04166667e+05 ... 1.04166667e+05\n",
      "  1.04166667e+05 1.04166677e-02]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (16,64) and (96,64) not aligned: 64 (dim 1) != 96 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mautoencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Winter_2023/BMI_203/final-nn/nn/nn.py:395\u001B[0m, in \u001B[0;36mNeuralNetwork.fit\u001B[0;34m(self, X_train, y_train, X_val, y_val)\u001B[0m\n\u001B[1;32m    392\u001B[0m per_epoch_loss_train\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[1;32m    394\u001B[0m _, cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(X_train)\n\u001B[0;32m--> 395\u001B[0m grad_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackprop\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_hat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_params(grad_dict)\n\u001B[1;32m    398\u001B[0m \u001B[38;5;66;03m# Save parameter update size\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;66;03m#update_sizes.append(np.abs(new_W - prev_W))\u001B[39;00m\n\u001B[1;32m    400\u001B[0m \n\u001B[1;32m    401\u001B[0m \u001B[38;5;66;03m# Compute validation loss\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Winter_2023/BMI_203/final-nn/nn/nn.py:289\u001B[0m, in \u001B[0;36mNeuralNetwork.backprop\u001B[0;34m(self, y, y_hat, cache)\u001B[0m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss function must be binary cross entropy or mean squared error.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# Pass param_dict values to single forward pass method\u001B[39;00m\n\u001B[0;32m--> 289\u001B[0m dA_prev, dW_curr, db_curr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_single_backprop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mW_curr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb_curr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mZ_curr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA_prev\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdA_curr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;66;03m# Make dictionary to store gradient values\u001B[39;00m\n\u001B[1;32m    292\u001B[0m grad_dict \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/Documents/Winter_2023/BMI_203/final-nn/nn/nn.py:229\u001B[0m, in \u001B[0;36mNeuralNetwork._single_backprop\u001B[0;34m(self, W_curr, b_curr, Z_curr, A_prev, dA_curr, activation_curr)\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;66;03m# dA_prev = (W_curr).T . dZ_curr\u001B[39;00m\n\u001B[1;32m    228\u001B[0m A_curr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sigmoid(Z_curr)\n\u001B[0;32m--> 229\u001B[0m dA_prev \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mW_curr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA_curr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;66;03m# dW_curr = 1/m * dZ_curr . (A_prev).T\u001B[39;00m\n\u001B[1;32m    232\u001B[0m dW_curr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m A_prev\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(dZ_curr, A_prev\u001B[38;5;241m.\u001B[39mT)\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: shapes (16,64) and (96,64) not aligned: 64 (dim 1) != 96 (dim 0)"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(X_train, y_train, X_val, y_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
